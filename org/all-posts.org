#+Title: microbo
#+Author: jthulhu
#+startup: overview
#+hugo_base_dir: ../

* Blog
:PROPERTIES:
:EXPORT_HUGO_SECTION: blog
:END:
** DONE Efficient streaming regular pattern matching :computer_science:paper:algorithm:
:PROPERTIES:
:EXPORT_FILE_NAME: efficient-streaming-regex-matching
:EXPORT_DATE: 2023-10-30
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :math true
:END:

Regular pattern matching is comes up very often, both in theoretical frameworks and in practice
and, as such, is a problem that has been studied a lot. The RAM model in which it is studied,
however, does not always take into account the practical difficulties that arise with very large
amount of data, which don't fit in memory. For this reason, it makes sense to study efficient
algorithms in a more realistic computational model, the streaming model.

*** Preliminary notions
Before diving into the main subject, let's first quickly understand what the problem actually is.
The streaming regular pattern matching problem is a generalition of a problem of great practical
importance, which is the pattern matching problem.

**** The pattern matching problem
Assume we have fixed a finite alphabet \(\Sigma\) for the rest of the article. Given strings
\(P\), the /pattern/, and \(T\), the /text/, over \(\Sigma\), we want to find all
occurences of \(P\) in \(T\). While the naive method takes \(O(nm)\) time, where
\(n=|T|\) and \(m=|P|\), the exist faster approaches that only take \(O(n+m)\) time[fn:kmp],
which is also clearly optimal (one has to read at least every character in \(P\) and in
\(T\)).

Yet, these algorithms are not optimal from a space complexity point of view: the naive algorithm
only takes \(\tilde O(1)\) space. As far as I know, there is no known algorithm that is optimal
both for the time and space complexity. However, counting the space complexity as we usually do
is not necessarily useful in this framework, because sometimes the text is so big that it simply
doesn't fit into memory (think of database managers which easily handle terabytes of data).

**** The streaming model
There exist several computation models that take into account the aforementioned problem. We will
focus on the /streaming model/, which corresponds to receiving the text character by character
(like as if you were reading it from a disk, or receiving it from over the internet). In this
scenario, reading a character /again/ once it has been seen is expensive or impossible. Instead,
every character that one wants to read again should be explicitely stored, and therefore counts
in the space complexity.

In this model, algorithms that take \(O(n+m)\) time and \(O(m)\) space are
optimal[fn:foolingset]. But we want to do /better/ (if we have a linear space complexity in a
streaming model, then we don't gain much information with respect to a classical model), which
means a space complexity that is sublinear in both \(n\) and \(m\). This is, in fact, impossible
even without any time restriction, but only in the deterministic case. If we consider the broader
class of algorithms to include Monte Carlo algorithms[fn:monte-carlo], then there exists a
refinement of the Robin-Karp algorithm that finds the occurences with high probability, and which
has a sublinear complexity: the Robin-Karp algorithm works by computing the hash of a pattern,
then computing the hash of every substring of the same length as the pattern, and comparing only
the hash, not the whole pattern. If the hash function is "random enough", this outputs true
occurences with high probability. Furthermore, in the original algorithm, the hash function is a
"rolling function"[fn:rolling], that is, if it is known for \(a_0a_1\ldots a_m\), it is easy to
compute for \(a_1a_2\ldots a_{m+1}\). The refinement of this algorithm makes it possible to
"roll" the hash without buffering a sliding window of \(m\) characters.

*** Regular expression matching
We might be interested in generalizing the problem to regular expression matching in the
streaming model: given a regular expression \(R\), for each character (that we receive in a
streaming fashion), we must say whether there is a substring of \(T\) that ends there and that
\(R\) matches. As before, we aim at a sublinear space complexity, but this is hard so, instead,
we'll get a complexity that is sublinear in the size of \(R\) and polynomial in \(d\), the
number of kleene star and disjunction operators in \(R\). If \(d\) is small before \(m\),
then this is indeed sublinear, and we are happy. Note that the parameter \(d\) has been
introduced because, in practice, it has been observed to be significantly smaller than \(m\).

The first step to achieve this result is to construct the [[https://en.wikipedia.org/wiki/Thompson%27s_construction][Thompson automata]] of \(R\). We observe
that parts of \(R\) that were simply concatenations of characters end up as sequences of nodes
that only have one outgoing transition (except for the last one). We can therefore pack together
these strings, which we will call /atomic strings/ of \(R\), and the resulting automaton has size
\(O(d)\). The main idea of the algorithm is then to find matches of the atomic strings using the
streaming pattern matching algorithm, and then to "stitch" together these matches into runs over
the automata. Indeed, for each atomic string, for each character of the text, we want to know
whether there is a substring of the text that ends on that character, and such that if we walk on
the automata, starting on the initial state, following that string, we end up on the last state
corresponding to that atomic string.

If we just do that, however, we have to keep too much information about the past matches of
atomic strings at any point in time. The first idea to make this work is to consider all prefixes
of atomic strings whose length is a power of two, in addition to the atomic strings themselves.
The set \(\Pi\) of these strings is called the set of /canonical prefixes/. We run the usual
streaming pattern matching algorithm "in parallel" for every string in \(\Pi\).  When a
canonical prefix \(P\in\Pi\) has an occurence, there are two cases.
- If the prefix is a single character, then there is a walk in the automata that corresponds to a
  suffix of the prefix of \(T\) seen so far ending with \(P\) if, and only if, there is such
  a walk ending with an atomic string \(A\) on the previous character, and \(P\) is reachable
  from the last state of \(A\) with ϵ-transitions (the set of such atomic strings is
  precomputed). This is easy to check: for every atomic string \(A\), we can remember if it has
  an occurence in the last character, and that fits in \(O(d)\) space.
- Otherwise, we consider \(P'\) the canonical prefix of half the size of \(P\) (or a bit
  more, if \(P\) is an atomic string). Now, to know whether there is a walk on the automata
  that ends with \(P\), it is sufficient to know whether there is a walk on the automata that
  ends with \(P'\), \(|P'|\) characters in the past. To know this, we must remember whether
  an index \(i\) has an occurence of any canonical prefix \(Q\) for \(|Q|\) characters,
  which, if done naively, requires too much memory. Solving this problem is the hard part of
  regular streaming matching.

**** Aperiodic canonical prefixes
But what if \(P'\) is periodic? Can we bound the number of occurences too? The answer is no, in
fact there can be /many/ occurences of periodic strings. What saves us in this case is that these
occurences have a nice structure, which allows us to encode efficiently the set of their
occurences.

More specifically, if there are enough occurences of a periodic string \(P\) in a given
substring of \(T\), and \(Q\) is the period of \(P\), then that substring is also a
substring of \(Q^\infty:= QQ\ldots\). In particular, the occurences will form a sequence with
an arithmetic progression. In order to store the occurences, we can then simply store the first
occurence and the number of following occurences.

That's enough to store efficiently the occurences, but we are interested only in /certain/
occurences of a canonical prefix \(P\): those that end a substring of \(T\) which also
corresponds to a walk in our automata, ending with \(P\). We call those occurences /witnesses/
of \(P\). The problem is that those witnesses do not have the same, nice structure as the set
of all the occurences of \(P\) in a given region, because not all occurences are witnesses.

This is where technicalities arise. To find the witnesses in among all the saved occurences, we
save not only the occurences of \(P\), but also the witnesses of the atomic strings that
"precede" \(P\) in the automata, that is, those for which there is a path composed of
ϵ-transitions from their last state to the first state of \(P\). To do so, we use the same
trick, recursively: we remember all the occurences of such an atomic string \(A\) near the
beginning of the first occurences of \(P\). \(A\) is aperiodic, then there is a constant
number of such occurences, so it's easy, we can simply store all the (recent) witnesses.
Otherwise, the occurences form an arithmetic progression, so we store only the first one and
their number. Again, to find witnesses among all the saved occurences, we apply the same
trick. If this is carefully done, we only need to recurse a logarithmic number of times with
respect to the size of the period of \(P\), therefore \(O(\log m)\).

Now, we need to "restore" the information that has been compressed. To do so, we reduce the
problem to a graph one: given a canonical prefix \(P'\), its compressed representation of
occurences, and its following canonical prefix \(P\), we want to know whether from the
occurences of \(P'\) at the beginning at the set (those that we have explicitely saved) to the
current occurence of \(P\), there is a walk on the automata the connects the end of \(P'\)
with the end of \(P\), and that corresponds to the characters that are present in \(T\) in
between. Of course, we have /not/ saved those characters, it would have taken too much space, but
we also know that that string is a substring of \(Q^\infty\). We therefore consider the graph
whose nodes are canonical prefixes and where two nodes are connected by an edge of weight \(d\)
if there is a walk with letters in \(Q^\infty\) from the first node to the second, of length
\(d\), with \(d\leq 10|Q|\). Now, the problem is simply whether there is a path of weight the
distance between the saved occurence of \(P'\) and \(P\) in that graph.

**** Finding weighted walks in graphs
Given a directed, weighted multi-graph \(G\), two nodes \(u\) and \(v\), and a target weight
\(x\), we want to know whether there is a path from \(u\) to \(v\) of weight \(x\). We solve this
problem using dynamic programming: for every pair of nodes and weight \(w\leq x\), we decide
whether there is a path from the first node to the second of weight \(w\): for any \(k\), we
consider \(C_k\) a matrix of bit-vectors. Intuitively, \(C_k[u,v][d]\) indicates whether there is
a path from \(u\) to \(v\) of weight \(d\), but only contains that information for \(d\leq
2^k\). Then, if we define \(\odot\) with

\[
  (A\odot B)[u,v][d] = \bigvee_{\substack{w\in V(G)\\ i\in \{0,\ldots,d\}}} A[u,w][i]\land B[w,v][d-i]
\]

we can compute \(C_{k+1}\) knowing \(C_k\) and \(C_0\), using the relation

\[ C_{k+1}=C_k\odot C_0\odot C_k \]

This relation is true because, for any path of weight \(d\leq 2^{k+1}\), there is an edge in
that path such that if it is removed, the two remaning paths have weight at most \(2^k\).

Observe that \(\odot\) is essentially computing convolutions (and taking the disjunction of the
results); we can therefore use the fast Fourier transform to compute it efficiently. If
\(x=O(|V(G)|)\), this doesn't use too much space. If \(x\) is large, however, we don't obtain
a sublinear complexity.

**** Circuit computations
In order to save space, we are going to encode our computation with circuits, and we are going to
find another field in which the computations are performed. Rather than working with booleans
indicating /whether/ there is a path of a given weight, we are going to work in
\(\mathbb{F}_p\) (for a certain \(p\in\mathbb{P}\)), and we are going to /count/ (modulo
\(p\), that is) the number of such paths.

The first step is efficiently finding a suitable \(p\), that is probably prime. I am going to
skip the details of this operation and assume that the \(p\) we have found has all the
properties we need with probability at least \(1/2\). Furthermore, to save space we can apply a
transformation on our circuit[fn:bringmann] which requires verifying that the circuit satisfies
some properties. All of the conditions are verified if we translate directly our previous
construction, with elements in \(\mathbb{F}_p\), but one: the circuit should not overflow.

To ensure that the circuit does not overflow, instead of doubling the weight of the paths at each
step, we multiply it by \(1+\varepsilon\), with \(\varepsilon=\frac1{\log x}\). I do not have
any intuition about why that helps besides the fact that, when you carry out the computation, it
Just Works^{©}.


[fn:kmp] Such as the [[https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm][KMP algorithm]], which is a particular case of the more general [[https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm][Aho-Corasick]]
    algorithm.

[fn:foolingset] Which can be shown using a [[https://en.wikipedia.org/wiki/Communication_complexity][fooling set technique]].

[fn:monte-carlo] In this context, a [[https://en.wikipedia.org/wiki/Monte_Carlo_algorithm][Monte-Carlo algorithm]] is an algorithm that
    never misses an occurence of the pattern, but might wrongly detect an occurence of the
    pattern, with probability at most \(n^{-c}\) for any constant \(c>0\) that is fixed
    beforehand.

[fn:distance] We consider the [[https://en.wikipedia.org/wiki/Hamming_distance][Hamming distance]] here, although the same problem
    with the [[https://en.wikipedia.org/wiki/Edit_distance][edit distance]] is also studied.

[fn:bringmann] The transformation is presented in the article /[[https://epubs.siam.org/doi/10.1137/1.9781611974782.69][A Near-Linear Pseudopolynomial Time
    Algorithm for Subset Sum]]/, by Bringmann. It consists in eagerly applying the Fourier
    transform to every input, which does not affect sum gates and simplifies the computation of
    convolution gates. Then, the final result is obtained by computing the inverse Fourier
    transform to the output of the circuit. With respect to that paper, though, the efficiency of
    the method presented here does not depend on the Extended Riemann Hypothesis; it is replaced
    with an application of the Bombieri-Vinogradov theorem.

[fn:rolling] A [[https://en.wikipedia.org/wiki/Rolling_hash][rolling hash]] can be implemented using, for instance, polynomials over a well-chosen
    ring: a string is seen as a sequence of coefficients of a polynomial. The hash is then simply
    the evaluation of that polynomial at a well-chosen point of the field. For instance, if one
    choses a number \(m\) and a multiplicative invertible element \(a\) in \(\mathbb{Z}_m\), one
    sees a string \(w=x_0\ldots x_n\) as the polynomial \(P_w=x_0 + x_1 X + \ldots x_n X^n\)
    (assuming the alphabet has size \(m\), to see letters as elements of \(\mathbb{Z}_m\)). The
    hash of such a string is then simply the evaluation (in \(\mathbb{Z}_m\))of \(P_w\) at \(a\):
    \(h(w)=P_w(a)\). Then, \[h(x_1\ldots x_{n+1})=x_1+\ldots+x_{n+1} a^n=\frac{h(x_0\ldots
    x_n)-x_0}{a}+x_{n+1}a^n\] which shows it's easy to "roll" \(h\).
** DONE Challenging TDD: can tests cover every feature?   :computer_science:
:PROPERTIES:
:EXPORT_DATE: 2023-11-02
:EXPORT_FILE_NAME: challenging-tdd
:END:

After having spent some time in the Pharo community, I have realized how much people rely on
tests, not only to find bugs, but as a core developping tool. In Pharo, the idea of TDD is really
pushed as far as it can go: the typical workflow is to write unit tests, run them, which of
course fails (because no other code has been written yet) complaining that a given method is not
implemented. This failure is caught by the Pharo runtime, which opens their cool debugger. The
important part is that the debugger allows you to write code right away, to fill up the missing
method. Then, you ask the debugger to continue the execution where it was left, and the Pharo VM
patches every live object to take into accounts the modifications you have done.

Not only this sounds very cool, as there are people who literally never ever code from outside
their debugger, but it also has a lot of good properties. You naturally don't write code that is
not covered by a test, since every line of code you write is written when a test needs it. This
entails that every piece of code you write has examples that use them: their unit tests. I have
heard of some people who say they don't need to write documentation, because they write clear and
concise unit tests, which act as the documentation. In fact, I have even heard a bold claim

#+begin_quote
  "If it's not tested, it's not a feature" --- Cueball
#+end_quote

After some search, I've realized that similar slogans are quite common among TDD enthusiasts ("/if
it's not tested, it's broken/", ...). And it's hard to argue with the facts: there is not a single
medium to big project that doesn't have a sizeable test suite, because /humans make mistakes/ and
/coding is hard/.


That being said, I've been puzzled for some time by that first sentence, "/if it's not tested,
it's not a feature/", which somehow implies that all features are testable. Is that really the
case? If not, how could I detect a bug in a feature that no test could reveal? The rest of this
post will be spent searching for this kind of bugs/features.

*** Detailed assumptions
First of all, the point here is *not* to say that a test suite is fundamentally incomplete, that
is, even if all the tests are green, there can still be bugs. In the formal verification lingo,
tests are said to be /unsound/. But that's fine. Tests have other purposes than to formally
certify a code base (documenting code, providing examples, tracking bugs, ...).

In fact, we will assume for the rest of this post that we /know/ what the bug is. We have a
minimal, reproducible example that exhibits it. We have infinite engineering budget, so we can
develop as much testing infrastructure as needed. We have an arbitrary amount of time, so our
tests can run as long as needed to reveal the bug. The question is: is there a bug for which we
still cannot write a test that exhibits it? Take some time to think about it. If you have no
clue, and think that it doesn't make sense to have a bug that is impossible to witness, stay with
me!

*** First attempts: randomness and side effects
Maybe you have already faced a similar situation in practice: you know there /is/ a bug, but you
fail to reproduce it. You try to write some tests that would exhibit it, following some
instructions an other user has provided you indicating what happened to them when they witnessed
the bug. Yet, frustratingly, you do not witness any bug yourself. If you have later realized what
was the cause for that bug, and why you couldn't reproduce it easily, you may have answered our
main question with one these cases. Most often, though, this does not qualify for the kind of
bugs I was looking for, and I'll try to explain why on some examples.

**** Randomness
What if the behavior of the program is non-deterministic, as in, it requires a source of
randomness to work (which is, in practice, extremely common because it is likely that the common
datastructures of your standard library do so). Then, you could run your program in the same
settings over and over again and, if you're unlucky enough (or lucky, from the point of view),
never witness that particular executation trace that exhibits a bug.

While this might seem like a valid example, it is not in my opinion because no program is truely
random (at least, not in the sense we are using here). Why? Because programs delegate the task of
getting randomness to others. Typically, when you have a pseudo-random number generator, you need
to initialize it with a random seed, otherwise you'll always get the same results, and there is
no random in it. The operating system can provide randomness, every cryptographically good; but
in a test environment, you mock the operating system. You are testing your program, not /your
program and the running operating system/. Remember that, in our setup, we already know where the
bug is and what it is, and we have infinite engineering budget, so it is feasible to mock the
operating system to give the exact random seed that will trigger the bug. Similarly, if you use
some external input as a seed (the user typing on their keyboard, whatever eletrical noise a
driver is reading, or if you have a magma lamp connected to your computer to provide /true/
randomness), that external input is /not/ part of the software you are testing, it is part of the
environment which contributes in modifying the software behavior, so you /can/ mock it.

**** Side effects
In fact, both of the previous attempts are examples of side effects, at the level of the program,
that is, ways to interact (may that be a read or a write operation) with the environment, in a
broad sense. Time itself, for instance, is part of the execution environment of a program, and,
even though it can only be read (that is, until our hardware includes time machines), it can lead
to non-determinism in our execution.

However, if we /fix/ the environment (by mocking it), then there is no longer a source of
randomness (this is not completely true, we'll come back on this later). This means that all the
bugs that rely on side effects are good examples of bugs that cannot be witnessed. In fact, we
will see in the next section that there are very simple bugs that cannot be witnessed, in a pure,
deterministic context, and that there is no need to "cheat" to find such an example.

*** Liveness and safety
Without further ado, let me reveal the first example we will consider: a program whose only
feature is that it terminates. A very simple noop. Now, consider that I am very stupid, and I
have introduced a bug in this (empty) program: I have accidentally introduced a never-ending
loop. How would I witness this bug? The answer is: I can't. After a finite amount of time, if my
program stopped then my I can assert that this execution does not witness the bug; otherwise, I
can't say anything. Whatever my program is doing, it might eventually stop, so I cannot be sure
that I am witnessing a bugged execution. But it might also never stop, so I cannot be sure that I
am witnessing a sane execution. In fact, deciding whether a program stops in general is
undecidable, so it is /strictly impossible/ to exhibit this bug with tests, even though in my
original example, it would be pretty easy to find the bug by reading it ("/Who's the idiot who
added a loop in the program that should literally do nothing?  They're fired!/").

In general, features can be classified as /liveness/ features or /safety/ features (or as a
combination of both, I'm not getting into technical details). A lifeness feature asserts that
something good will eventually happen, whereas a safety feature asserts that something bad will
never happen. And, while it is easy to imagine a test that checks that there is no safety bug
(because if there is one, it will happen in finite time by definition), liveness bugs cannot be
tested, because if something good has yet to happen, that doesn't tell me whether it's going to
happen one day or not.

Some example of liveness features that are important in real life:
 - my scheduler will, eventually, run a given task;
 - my database manager will, eventually, be in a consistent state;
 - my network packet will, eventually, reach whomever it was sent to;
 - my compiler will, eventually, stop its optimisation passes and generate code;
 - my filesystem will, eventually, flush my IO operations and /save my file on disk/;
 - my mutex will, eventually, be realsed so that I can aquire it and go on with my life;
 - ...

Liveness features represent an important family of properties of programs, yet, according to
Cueball, "/if it's not tested, it's not a feature/". Are you still convinced by that claim?

However, the worst has yet to come...

*** Non-determinism, second attempt
Remember as I claimed, earlier, that there is no primitive in a language that is /simply
non-deterministic/, and that I would need to ask for an external source of non-determinism? Well,
that's simply not true, in general. To understand better the arguments presented onwards, I'll
talk briefly about /execution traces/, that I have already mentioned.

For the sake of simplicity, let's assume that the execution of a program can be modeled as a
sequence of states. At each step, you pass to the next state. Beware that, countrary to Turing
machines, the number of states is not necessarily bounded. Indeed, if you consider the set of
configurations of a Turing machine (a configuration is the information about the state the Turing
machine currently is, as well as everything that is written on every tape and the positions of
the tape heads), that is a valid set of state that encompasses every possible execution of any
program on a particular Turing machine. We call an execution trace of a program, in a given
environment, "the" sequence of the states of the program, step after step.

I have put /the/ between double quotes because when there is a non-deterministic operation, there
might be multiple possible execution traces after that operation is executed. Now, most of the
time the set of possible execution traces is a singleton, containing the /only/ possible
execution trace (when your program is deterministic). But what if it's not? What if there are,
say, two execution traces, one exhibiting the bug, and not the other. How would you test that?
Remember, you can alter however you want the environment but you cannot change the semantics of
the programming language your software was written into.

Maybe some are thinking that, if the software is non-deterministic, you can simply repeat the
test a large number of times; if the probability of triggering the bug is non-zero, then you have
a very high probability of witnessing it at some point. After all, if we can witness it in finite
time almost surely (ie. with probability \(1\)), maybe that's enough to consider that we were
able to trigger the bug with a test. But this reasoning is fundamentally flawed: there is no
reason to believe there is a distribution of probability over the results of non-deterministic
operations. To put it in other words, what if I have an operation which returns a boolean
non-deterministically by sending a mail to Cueball asking him what the result should be. What is
the probability of Knuth answering true? That is non-sensical. He could very well decide to
always answer false in production, and true during the tests.

While this particular case might look a bit contrieved, there are similar situations that arise
/very/ often in real life. The typical example is when you use an underspecified API: the
behavior of whatever resource you're using is not fully described. When you test it locally, it
behaves in a certain way (that is coherent with its specification), but when you deploy it
somewhere else, the resource is implemented in a different way (which still adheres to the
specification), which screws up your code. The behavior of the resource is non-deterministic,
because several things might happen when you interact with it, but, in /your/ testing
environment, not all of the possible traces can actually happen. You can only see a subset of
them.

*** The ultimate challenger: UB
If you think carefully about what was said in the paragraph about the set of execution traces,
there are three possible cases, but we have only mentioned two:
- the set of execution traces is a singleton, the execution is deterministic, everything goes
  well;
- the set of execution traces has at least two traces, the execution is non-deterministic, things
  get /weird/;
- the set of executions traces is empty, things get /weirder/.

How could it be that the set of execution traces is empty? Intuitively, it doesn't make sense for
a programming language to have non-deterministic operations that simply have zero possible
outcomes (and diverging counts as an outcode). Yet, it turns out that most "low-level"
programming languages some operations are considered /Undefined Behavior/, that is, no defined
behavior corresponds to that operation. At the language abstract machine level, if you were to
try to "execute" a program with no valid execution trace, it would throw an error (but, with
respect to the program, it would be a meta-error, similar to a type error, not something that you
could catch). But, it is in general undecidable whether a given program leads to undefined
behavior, and compilers /have/ to output something when the behavior is not undefined, so /it
happens/ that a program with no behavior is executed. In this case, nothing has meaning anymore:
by observing the behavior of the /executed/ program, you can obtain no information on "its trace"
(since there is no such thing).

Typically, this is the difference between what the C standard calls "undefined behavior" and
"unspecified behavior". The former has no execution traces, the latter has more than one.

In particular, it is possible for a bug leading to undefined behavior not to be detectable by
simply witnessing the execution of a program. It might seem weird to say that a program has no
execution trace while it is clearly executing before your eyes; this is one of the common
pitfalls one might fall into while reasoning on UB. I suggest reading [[https://www.ralfj.de/blog/2019/07/14/uninit.html]["What the Hardware Does" is
not What Your Program Does]], which does a pretty good job at explaning why it's impossible to
test "at the hardware level" bugs that lead to UB.

** DONE The periodicity lemma: two elegant proofs   :computer_science:paper:
:PROPERTIES:
:EXPORT_FILE_NAME: word-periodicity-lemma
:EXPORT_DATE: 2023-11-07
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :math true
:END:
The periodicity lemma is a widely useful result about word combinatorics. Yet, the paper that if
often cited as the source for its proof, /Uniqueness Theorems for Periodic Functions/, uses very
unusual techniques in stringology.

#+begin_lemma
If a word \(w\) has periods \(p\) and \(q\), and is of length at least \(p+q-\gcd(p, q)\), then
\(w\) has period \(\gcd(p,q)\).
#+end_lemma

Before proving this stronger version of the lemma, let us state a weaker version. The point is
that this alternative version has a purely combinatorics proof, that is also interesting /per
se/.

#+begin_lemma
If a word \(w\) has periods \(p\) and \(q\), and is of length at least \(p+q\), then \(w\) has
period \(\gcd(p, q)\).
#+end_lemma
#+begin_proof
Assume \(q\geq p\). We are going to mimick Euclid's algorithm for computing \(\gcd(p, q)\). If
\(p=q\), the result is clear.

Otherwise, let \(i \leq |w|-(q-p)\) be a position in \(w\). If \(q\leq |w|\),
\(w[i]=w[i+q]\). Futhermore, \(w[i+q-p]=w[i+q]\). Hence \[w[i]=w[i+(q-p)]\]
Similarly, in the case, \(i-p\geq1\), and therefore \(w[i-p]=w[i]\). Since \(w[i-p]=w[i-p+q]\),
we have the same result. This means that \(q-p\) is a period of \(|w|\).

Note that \(\gcd(p, q-p)=\gcd(q, p)\) and that we certainly have \(p+(q-p)-\gcd(p,
q)\leq|w|\). By induction (on \(p+q\), for instance"), the result holds.
#+end_proof

*** A useful fact
Before giving two proofs of the lemma, we are going to show a very simple fact that will turn out
to be useful for both proofs.

#+begin_fact
Let \(w\) be a word with periods \(p\) and \(q\). \(w\) has period \(\gcd(p, q)\) if, and only
if, it can be extended in an infinite word that also has periods \(p\) and \(q\).
#+end_fact
#+begin_proof
If \(w\) is \(\gcd(p, q)\)-periodic, then it can be extended to an infinite word that is
\(\gcd(p, q)\)-periodic, and thus, that is also \(p\) and \(q\) periodic.

Conversely, if \(w\) can be extended in such an infinite word \(\hat{w}\), then \(\hat{w}\) is
\(\gcd(p,q)\)-periodic (which can be seen using the same proof as in the weak form of the
lemma). Hence, since \(w\) is a subword of \(\hat{w}\), it is also \(\gcd(p,q)\)-periodic.
#+end_proof

*** Formal series proof
Let us now, without further ado, give the first proof of the original lemma.
#+begin_proof
Consider \((a_n)_{n\in\mathbb{N}}\) (resp. \((b_n)_{n\in\mathbb{N}}\)) \(p\)-periodic (resp.
\(q\)-periodic) sequence which extends \(w\). Let \(F\) (resp. \(G\)) be the formal series \[
  F = \sum_{n=0}^\infty a_n X^n
\] respectively \[
  G = \sum_{n=0}^\infty b_n X^n
\]
By periodicity of \((a_n)\) and \((b_n)\), there exists polynomials \(P\) and \(Q\) of degree at
most, respectively, \(p-1\) and \(q-1\), such that \(F=(1-X^p)^{-1}P\) and \(G=(1-X^q)^{-1}Q\).

Then, let \(H=F-G\). We can write \(H=\dfrac{(1-X^q)P-(1-X^p)Q}{(1-X^p)(1-X^q)}\). Since \[
1-X^{\gcd(p, q)}\mid{}1-X^p,1-X^q \] and since the degree of \((1-X^q)P-(1-X^p)Q\) is at most
\(R\) is at most \(p+q-\gcd(p,q)\). Hence, \[R = H\dfrac{(1-X^p)}{1-X^{\gcd(p,q)}} \equiv
0\mod{}X^{p+q-\gcd(p,q)}\] because, by hypothesis, \(H \equiv 0 \mod{} X^{p+q-\gcd(p,q)}\) and
\(\dfrac{(1-X^p)(1-X^q)}{1-X^{\gcd(p,q)}}\) is a polynomial.

Hence, \(R=0\) and thus \(H=0\), proving that \(F=G\). By using the Fact, we have that \(w\) is
\(\gcd(p, q)\)-periodic.
#+end_proof

*** Linear algebra proof
This second proof of the lemma will prove a slightly stronger statement: the length bound of
\(p+q-\gcd(p,q)\) is optimal, that is, for any \(p\) and \(q\), there is a word \(w\) with
periods \(p\) and \(q\) of length \(p+q-\gcd(p,q)-1\) and which is not \(\gcd(p,q)\)-periodic.

#+begin_proof
As before, consider \(a\) and \(b\) the sequences that extend \(w\) and that are, respectively,
\(p\) and \(q\) periodic. By Fourier transform, there exists
\((c_\omega)_{\omega\in\mathbb{U}_p}\) and \((d_\xi)_{\xi\in\mathbb{U}_q}\), such that, for all
\(n\in\mathbb{N}\), \[ a_n = \sum_{\omega\in\mathbb{U}_p} c_\omega \omega^n \] and \[ b_n =
\sum_{\xi\in\mathbb{U}_q} d_\xi xi^n \]

Now, by hypothesis, for any \(n=1,\ldots,p+q-\gcd(p,q)\), we have \(a_n-b_n=0\). This defines a
system of \(p+q-\gcd(p,q)\) linear equation in the \(p+q-\gcd(p,q)\) unknowns \(c_\omega\),
\(-d_\xi\) for \(\omega\neq\xi\) and \(c_\omega-d_\xi\) for \(\omega=\xi\). The matrix of this
system is a Vandermonde matrix, hence it is non-singular. Thus, for \(\omega \in \mathbb{U}_p
\backslash \mathbb{U}_q\), \(c_\omega=0\) (and similarly for \(q\)-th root of the unity \(\xi\)
which are not also \(p\)-th root of the unity, \(d_\xi=0\)), and for other \(\omega=\xi \in
\mathbb{U}_p \cap \mathbb{U}_q\), \(c_\omega=d_\xi\). Therefore, for all \(n\in\mathbb{N}\),
\(a_n=b_n\). In particular, using the Fact, \(w\) is \(\gcd(p,q)\)-periodic.
#+end_proof

Observe that, if we had less that \(p+q-\gcd(p,q)\) equations, then there would be a non-trivial
linear subspace of solutions \((a, b)\) whose common prefix is \(p\)- and \(q\)-periodic. But,
only one point of that linear subspace hasa a common prefix that is \(\gcd(p,q)\)-periodic.
* Home
:PROPERTIES:
:EXPORT_HUGO_SECTION: /
:END:
** Search
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :layout search
:EXPORT_FILE_NAME: search
:END:
