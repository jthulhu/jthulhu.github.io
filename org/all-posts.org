#+Title: microbo
#+Author: jthulhu
#+startup: overview
#+hugo_base_dir: ../

* Blog
:PROPERTIES:
:EXPORT_HUGO_SECTION: blog
:END:
** DONE Efficient streaming regular pattern matching :computer_science:paper:algorithm:
:PROPERTIES:
:EXPORT_FILE_NAME: efficient-streaming-regex-matching
:EXPORT_DATE: 2023-10-30
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :math true
:END:

Regular pattern matching is comes up very often, both in theoretical frameworks and in practice
and, as such, is a problem that has been studied a lot. The RAM model in which it is studied,
however, does not always take into account the practical difficulties that arise with very large
amount of data, which don't fit in memory. For this reason, it makes sense to study efficient
algorithms in a more realistic computational model, the streaming model.

*** Preliminary notions
Before diving into the main subject, let's first quickly understand what the problem actually is.
The streaming regular pattern matching problem is a generalition of a problem of great practical
importance, which is the pattern matching problem.

**** The pattern matching problem
Assume we have fixed a finite alphabet \(\Sigma\) for the rest of the article. Given strings
\(P\), the /pattern/, and \(T\), the /text/, over \(\Sigma\), we want to find all
occurences of \(P\) in \(T\). While the naive method takes \(O(nm)\) time, where
\(n=|T|\) and \(m=|P|\), the exist faster approaches that only take \(O(n+m)\) time[fn:kmp],
which is also clearly optimal (one has to read at least every character in \(P\) and in
\(T\)).

Yet, these algorithms are not optimal from a space complexity point of view: the naive algorithm
only takes \(\tilde O(1)\) space. As far as I know, there is no known algorithm that is optimal
both for the time and space complexity. However, counting the space complexity as we usually do
is not necessarily useful in this framework, because sometimes the text is so big that it simply
doesn't fit into memory (think of database managers which easily handle terabytes of data).

**** The streaming model
There exist several computation models that take into account the aforementioned problem. We will
focus on the /streaming model/, which corresponds to receiving the text character by character
(like as if you were reading it from a disk, or receiving it from over the internet). In this
scenario, reading a character /again/ once it has been seen is expensive or impossible. Instead,
every character that one wants to read again should be explicitely stored, and therefore counts
in the space complexity.

In this model, algorithms that take \(O(n+m)\) time and \(O(m)\) space are
optimal[fn:foolingset]. But we want to do /better/ (if we have a linear space complexity in a
streaming model, then we don't gain much information with respect to a classical model), which
means a space complexity that is sublinear in both \(n\) and \(m\). This is, in fact, impossible
even without any time restriction, but only in the deterministic case. If we consider the broader
class of algorithms to include Monte Carlo algorithms[fn:monte-carlo], then there exists a
refinement of the Robin-Karp algorithm that finds the occurences with high probability, and which
has a sublinear complexity: the Robin-Karp algorithm works by computing the hash of a pattern,
then computing the hash of every substring of the same length as the pattern, and comparing only
the hash, not the whole pattern. If the hash function is "random enough", this outputs true
occurences with high probability. Furthermore, in the original algorithm, the hash function is a
"rolling function"[fn:rolling], that is, if it is known for \(a_0a_1\ldots a_m\), it is easy to
compute for \(a_1a_2\ldots a_{m+1}\). The refinement of this algorithm makes it possible to
"roll" the hash without buffering a sliding window of \(m\) characters.

*** Regular expression matching
We might be interested in generalizing the problem to regular expression matching in the
streaming model: given a regular expression \(R\), for each character (that we receive in a
streaming fashion), we must say whether there is a substring of \(T\) that ends there and that
\(R\) matches. As before, we aim at a sublinear space complexity, but this is hard so, instead,
we'll get a complexity that is sublinear in the size of \(R\) and polynomial in \(d\), the
number of kleene star and disjunction operators in \(R\). If \(d\) is small before \(m\),
then this is indeed sublinear, and we are happy. Note that the parameter \(d\) has been
introduced because, in practice, it has been observed to be significantly smaller than \(m\).

The first step to achieve this result is to construct the [[https://en.wikipedia.org/wiki/Thompson%27s_construction][Thompson automata]] of \(R\). We observe
that parts of \(R\) that were simply concatenations of characters end up as sequences of nodes
that only have one outgoing transition (except for the last one). We can therefore pack together
these strings, which we will call /atomic strings/ of \(R\), and the resulting automaton has size
\(O(d)\). The main idea of the algorithm is then to find matches of the atomic strings using the
streaming pattern matching algorithm, and then to "stitch" together these matches into runs over
the automata. Indeed, for each atomic string, for each character of the text, we want to know
whether there is a substring of the text that ends on that character, and such that if we walk on
the automata, starting on the initial state, following that string, we end up on the last state
corresponding to that atomic string.

If we just do that, however, we have to keep too much information about the past matches of
atomic strings at any point in time. The first idea to make this work is to consider all prefixes
of atomic strings whose length is a power of two, in addition to the atomic strings themselves.
The set \(\Pi\) of these strings is called the set of /canonical prefixes/. We run the usual
streaming pattern matching algorithm "in parallel" for every string in \(\Pi\).  When a
canonical prefix \(P\in\Pi\) has an occurence, there are two cases.
- If the prefix is a single character, then there is a walk in the automata that corresponds to a
  suffix of the prefix of \(T\) seen so far ending with \(P\) if, and only if, there is such
  a walk ending with an atomic string \(A\) on the previous character, and \(P\) is reachable
  from the last state of \(A\) with ϵ-transitions (the set of such atomic strings is
  precomputed). This is easy to check: for every atomic string \(A\), we can remember if it has
  an occurence in the last character, and that fits in \(O(d)\) space.
- Otherwise, we consider \(P'\) the canonical prefix of half the size of \(P\) (or a bit
  more, if \(P\) is an atomic string). Now, to know whether there is a walk on the automata
  that ends with \(P\), it is sufficient to know whether there is a walk on the automata that
  ends with \(P'\), \(|P'|\) characters in the past. To know this, we must remember whether
  an index \(i\) has an occurence of any canonical prefix \(Q\) for \(|Q|\) characters,
  which, if done naively, requires too much memory. Solving this problem is the hard part of
  regular streaming matching.

**** Aperiodic canonical prefixes
But what if \(P'\) is periodic? Can we bound the number of occurences too? The answer is no, in
fact there can be /many/ occurences of periodic strings. What saves us in this case is that these
occurences have a nice structure, which allows us to encode efficiently the set of their
occurences.

More specifically, if there are enough occurences of a periodic string \(P\) in a given
substring of \(T\), and \(Q\) is the period of \(P\), then that substring is also a
substring of \(Q^\infty:= QQ\ldots\). In particular, the occurences will form a sequence with
an arithmetic progression. In order to store the occurences, we can then simply store the first
occurence and the number of following occurences.

That's enough to store efficiently the occurences, but we are interested only in /certain/
occurences of a canonical prefix \(P\): those that end a substring of \(T\) which also
corresponds to a walk in our automata, ending with \(P\). We call those occurences /witnesses/
of \(P\). The problem is that those witnesses do not have the same, nice structure as the set
of all the occurences of \(P\) in a given region, because not all occurences are witnesses.

This is where technicalities arise. To find the witnesses in among all the saved occurences, we
save not only the occurences of \(P\), but also the witnesses of the atomic strings that
"precede" \(P\) in the automata, that is, those for which there is a path composed of
ϵ-transitions from their last state to the first state of \(P\). To do so, we use the same
trick, recursively: we remember all the occurences of such an atomic string \(A\) near the
beginning of the first occurences of \(P\). \(A\) is aperiodic, then there is a constant
number of such occurences, so it's easy, we can simply store all the (recent) witnesses.
Otherwise, the occurences form an arithmetic progression, so we store only the first one and
their number. Again, to find witnesses among all the saved occurences, we apply the same
trick. If this is carefully done, we only need to recurse a logarithmic number of times with
respect to the size of the period of \(P\), therefore \(O(\log m)\).

Now, we need to "restore" the information that has been compressed. To do so, we reduce the
problem to a graph one: given a canonical prefix \(P'\), its compressed representation of
occurences, and its following canonical prefix \(P\), we want to know whether from the
occurences of \(P'\) at the beginning at the set (those that we have explicitely saved) to the
current occurence of \(P\), there is a walk on the automata the connects the end of \(P'\)
with the end of \(P\), and that corresponds to the characters that are present in \(T\) in
between. Of course, we have /not/ saved those characters, it would have taken too much space, but
we also know that that string is a substring of \(Q^\infty\). We therefore consider the graph
whose nodes are canonical prefixes and where two nodes are connected by an edge of weight \(d\)
if there is a walk with letters in \(Q^\infty\) from the first node to the second, of length
\(d\), with \(d\leq 10|Q|\). Now, the problem is simply whether there is a path of weight the
distance between the saved occurence of \(P'\) and \(P\) in that graph.

**** Finding weighted walks in graphs
Given a directed, weighted multi-graph \(G\), two nodes \(u\) and \(v\), and a target weight
\(x\), we want to know whether there is a path from \(u\) to \(v\) of weight \(x\). We solve this
problem using dynamic programming: for every pair of nodes and weight \(w\leq x\), we decide
whether there is a path from the first node to the second of weight \(w\): for any \(k\), we
consider \(C_k\) a matrix of bit-vectors. Intuitively, \(C_k[u,v][d]\) indicates whether there is
a path from \(u\) to \(v\) of weight \(d\), but only contains that information for \(d\leq
2^k\). Then, if we define \(\odot\) with

\[
  (A\odot B)[u,v][d] = \bigvee_{\substack{w\in V(G)\\ i\in \{0,\ldots,d\}}} A[u,w][i]\land B[w,v][d-i]
\]

we can compute \(C_{k+1}\) knowing \(C_k\) and \(C_0\), using the relation

\[ C_{k+1}=C_k\odot C_0\odot C_k \]

This relation is true because, for any path of weight \(d\leq 2^{k+1}\), there is an edge in
that path such that if it is removed, the two remaning paths have weight at most \(2^k\).

Observe that \(\odot\) is essentially computing convolutions (and taking the disjunction of the
results); we can therefore use the fast Fourier transform to compute it efficiently. If
\(x=O(|V(G)|)\), this doesn't use too much space. If \(x\) is large, however, we don't obtain
a sublinear complexity.

**** Circuit computations
In order to save space, we are going to encode our computation with circuits, and we are going to
find another field in which the computations are performed. Rather than working with booleans
indicating /whether/ there is a path of a given weight, we are going to work in
\(\mathbb{F}_p\) (for a certain \(p\in\mathbb{P}\)), and we are going to /count/ (modulo
\(p\), that is) the number of such paths.

The first step is efficiently finding a suitable \(p\), that is probably prime. I am going to
skip the details of this operation and assume that the \(p\) we have found has all the
properties we need with probability at least \(1/2\). Furthermore, to save space we can apply a
transformation on our circuit[fn:bringmann] which requires verifying that the circuit satisfies
some properties. All of the conditions are verified if we translate directly our previous
construction, with elements in \(\mathbb{F}_p\), but one: the circuit should not overflow.

To ensure that the circuit does not overflow, instead of doubling the weight of the paths at each
step, we multiply it by \(1+\varepsilon\), with \(\varepsilon=\frac1{\log x}\). I do not have
any intuition about why that helps besides the fact that, when you carry out the computation, it
Just Works^{©}.


[fn:kmp] Such as the [[https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm][KMP algorithm]], which is a particular case of the more general [[https://en.wikipedia.org/wiki/Aho%E2%80%93Corasick_algorithm][Aho-Corasick]]
    algorithm.

[fn:foolingset] Which can be shown using a [[https://en.wikipedia.org/wiki/Communication_complexity][fooling set technique]].

[fn:monte-carlo] In this context, a [[https://en.wikipedia.org/wiki/Monte_Carlo_algorithm][Monte-Carlo algorithm]] is an algorithm that
    never misses an occurence of the pattern, but might wrongly detect an occurence of the
    pattern, with probability at most \(n^{-c}\) for any constant \(c>0\) that is fixed
    beforehand.

[fn:distance] We consider the [[https://en.wikipedia.org/wiki/Hamming_distance][Hamming distance]] here, although the same problem
    with the [[https://en.wikipedia.org/wiki/Edit_distance][edit distance]] is also studied.

[fn:bringmann] The transformation is presented in the article /[[https://epubs.siam.org/doi/10.1137/1.9781611974782.69][A Near-Linear Pseudopolynomial Time
    Algorithm for Subset Sum]]/, by Bringmann. It consists in eagerly applying the Fourier
    transform to every input, which does not affect sum gates and simplifies the computation of
    convolution gates. Then, the final result is obtained by computing the inverse Fourier
    transform to the output of the circuit. With respect to that paper, though, the efficiency of
    the method presented here does not depend on the Extended Riemann Hypothesis; it is replaced
    with an application of the Bombieri-Vinogradov theorem.

[fn:rolling] A [[https://en.wikipedia.org/wiki/Rolling_hash][rolling hash]] can be implemented using, for instance, polynomials over a well-chosen
    ring: a string is seen as a sequence of coefficients of a polynomial. The hash is then simply
    the evaluation of that polynomial at a well-chosen point of the field. For instance, if one
    choses a number \(m\) and a multiplicative invertible element \(a\) in \(\mathbb{Z}_m\), one
    sees a string \(w=x_0\ldots x_n\) as the polynomial \(P_w=x_0 + x_1 X + \ldots x_n X^n\)
    (assuming the alphabet has size \(m\), to see letters as elements of \(\mathbb{Z}_m\)). The
    hash of such a string is then simply the evaluation (in \(\mathbb{Z}_m\))of \(P_w\) at \(a\):
    \(h(w)=P_w(a)\). Then, \[h(x_1\ldots x_{n+1})=x_1+\ldots+x_{n+1} a^n=\frac{h(x_0\ldots
    x_n)-x_0}{a}+x_{n+1}a^n\] which shows it's easy to "roll" \(h\).
** DONE Challenging TDD: can tests cover every feature?   :computer_science:
:PROPERTIES:
:EXPORT_DATE: 2023-11-02
:EXPORT_FILE_NAME: challenging-tdd
:END:

After having spent some time in the Pharo community, I have realized how much people rely on
tests, not only to find bugs, but as a core developping tool. In Pharo, the idea of TDD is really
pushed as far as it can go: the typical workflow is to write unit tests, run them, which of
course fails (because no other code has been written yet) complaining that a given method is not
implemented. This failure is caught by the Pharo runtime, which opens their cool debugger. The
important part is that the debugger allows you to write code right away, to fill up the missing
method. Then, you ask the debugger to continue the execution where it was left, and the Pharo VM
patches every live object to take into accounts the modifications you have done.

Not only this sounds very cool, as there are people who literally never ever code from outside
their debugger, but it also has a lot of good properties. You naturally don't write code that is
not covered by a test, since every line of code you write is written when a test needs it. This
entails that every piece of code you write has examples that use them: their unit tests. I have
heard of some people who say they don't need to write documentation, because they write clear and
concise unit tests, which act as the documentation. In fact, I have even heard a bold claim

#+begin_quote
  "If it's not tested, it's not a feature" --- Cueball
#+end_quote

After some search, I've realized that similar slogans are quite common among TDD enthusiasts ("/if
it's not tested, it's broken/", ...). And it's hard to argue with the facts: there is not a single
medium to big project that doesn't have a sizeable test suite, because /humans make mistakes/ and
/coding is hard/.


That being said, I've been puzzled for some time by that first sentence, "/if it's not tested,
it's not a feature/", which somehow implies that all features are testable. Is that really the
case? If not, how could I detect a bug in a feature that no test could reveal? The rest of this
post will be spent searching for this kind of bugs/features.

*** Detailed assumptions
First of all, the point here is *not* to say that a test suite is fundamentally incomplete, that
is, even if all the tests are green, there can still be bugs. In the formal verification lingo,
tests are said to be /unsound/. But that's fine. Tests have other purposes than to formally
certify a code base (documenting code, providing examples, tracking bugs, ...).

In fact, we will assume for the rest of this post that we /know/ what the bug is. We have a
minimal, reproducible example that exhibits it. We have infinite engineering budget, so we can
develop as much testing infrastructure as needed. We have an arbitrary amount of time, so our
tests can run as long as needed to reveal the bug. The question is: is there a bug for which we
still cannot write a test that exhibits it? Take some time to think about it. If you have no
clue, and think that it doesn't make sense to have a bug that is impossible to witness, stay with
me!

*** First attempts: randomness and side effects
Maybe you have already faced a similar situation in practice: you know there /is/ a bug, but you
fail to reproduce it. You try to write some tests that would exhibit it, following some
instructions an other user has provided you indicating what happened to them when they witnessed
the bug. Yet, frustratingly, you do not witness any bug yourself. If you have later realized what
was the cause for that bug, and why you couldn't reproduce it easily, you may have answered our
main question with one these cases. Most often, though, this does not qualify for the kind of
bugs I was looking for, and I'll try to explain why on some examples.

**** Randomness
What if the behavior of the program is non-deterministic, as in, it requires a source of
randomness to work (which is, in practice, extremely common because it is likely that the common
datastructures of your standard library do so). Then, you could run your program in the same
settings over and over again and, if you're unlucky enough (or lucky, from the point of view),
never witness that particular executation trace that exhibits a bug.

While this might seem like a valid example, it is not in my opinion because no program is truely
random (at least, not in the sense we are using here). Why? Because programs delegate the task of
getting randomness to others. Typically, when you have a pseudo-random number generator, you need
to initialize it with a random seed, otherwise you'll always get the same results, and there is
no random in it. The operating system can provide randomness, every cryptographically good; but
in a test environment, you mock the operating system. You are testing your program, not /your
program and the running operating system/. Remember that, in our setup, we already know where the
bug is and what it is, and we have infinite engineering budget, so it is feasible to mock the
operating system to give the exact random seed that will trigger the bug. Similarly, if you use
some external input as a seed (the user typing on their keyboard, whatever eletrical noise a
driver is reading, or if you have a magma lamp connected to your computer to provide /true/
randomness), that external input is /not/ part of the software you are testing, it is part of the
environment which contributes in modifying the software behavior, so you /can/ mock it.

**** Side effects
In fact, both of the previous attempts are examples of side effects, at the level of the program,
that is, ways to interact (may that be a read or a write operation) with the environment, in a
broad sense. Time itself, for instance, is part of the execution environment of a program, and,
even though it can only be read (that is, until our hardware includes time machines), it can lead
to non-determinism in our execution.

However, if we /fix/ the environment (by mocking it), then there is no longer a source of
randomness (this is not completely true, we'll come back on this later). This means that all the
bugs that rely on side effects are good examples of bugs that cannot be witnessed. In fact, we
will see in the next section that there are very simple bugs that cannot be witnessed, in a pure,
deterministic context, and that there is no need to "cheat" to find such an example.

*** Liveness and safety
Without further ado, let me reveal the first example we will consider: a program whose only
feature is that it terminates. A very simple noop. Now, consider that I am very stupid, and I
have introduced a bug in this (empty) program: I have accidentally introduced a never-ending
loop. How would I witness this bug? The answer is: I can't. After a finite amount of time, if my
program stopped then my I can assert that this execution does not witness the bug; otherwise, I
can't say anything. Whatever my program is doing, it might eventually stop, so I cannot be sure
that I am witnessing a bugged execution. But it might also never stop, so I cannot be sure that I
am witnessing a sane execution. In fact, deciding whether a program stops in general is
undecidable, so it is /strictly impossible/ to exhibit this bug with tests, even though in my
original example, it would be pretty easy to find the bug by reading it ("/Who's the idiot who
added a loop in the program that should literally do nothing?  They're fired!/").

In general, features can be classified as /liveness/ features or /safety/ features (or as a
combination of both, I'm not getting into technical details). A lifeness feature asserts that
something good will eventually happen, whereas a safety feature asserts that something bad will
never happen. And, while it is easy to imagine a test that checks that there is no safety bug
(because if there is one, it will happen in finite time by definition), liveness bugs cannot be
tested, because if something good has yet to happen, that doesn't tell me whether it's going to
happen one day or not.

Some example of liveness features that are important in real life:
 - my scheduler will, eventually, run a given task;
 - my database manager will, eventually, be in a consistent state;
 - my network packet will, eventually, reach whomever it was sent to;
 - my compiler will, eventually, stop its optimisation passes and generate code;
 - my filesystem will, eventually, flush my IO operations and /save my file on disk/;
 - my mutex will, eventually, be realsed so that I can aquire it and go on with my life;
 - ...

Liveness features represent an important family of properties of programs, yet, according to
Cueball, "/if it's not tested, it's not a feature/". Are you still convinced by that claim?

However, the worst has yet to come...

*** Non-determinism, second attempt
Remember as I claimed, earlier, that there is no primitive in a language that is /simply
non-deterministic/, and that I would need to ask for an external source of non-determinism? Well,
that's simply not true, in general. To understand better the arguments presented onwards, I'll
talk briefly about /execution traces/, that I have already mentioned.

For the sake of simplicity, let's assume that the execution of a program can be modeled as a
sequence of states. At each step, you pass to the next state. Beware that, countrary to Turing
machines, the number of states is not necessarily bounded. Indeed, if you consider the set of
configurations of a Turing machine (a configuration is the information about the state the Turing
machine currently is, as well as everything that is written on every tape and the positions of
the tape heads), that is a valid set of state that encompasses every possible execution of any
program on a particular Turing machine. We call an execution trace of a program, in a given
environment, "the" sequence of the states of the program, step after step.

I have put /the/ between double quotes because when there is a non-deterministic operation, there
might be multiple possible execution traces after that operation is executed. Now, most of the
time the set of possible execution traces is a singleton, containing the /only/ possible
execution trace (when your program is deterministic). But what if it's not? What if there are,
say, two execution traces, one exhibiting the bug, and not the other. How would you test that?
Remember, you can alter however you want the environment but you cannot change the semantics of
the programming language your software was written into.

Maybe some are thinking that, if the software is non-deterministic, you can simply repeat the
test a large number of times; if the probability of triggering the bug is non-zero, then you have
a very high probability of witnessing it at some point. After all, if we can witness it in finite
time almost surely (ie. with probability \(1\)), maybe that's enough to consider that we were
able to trigger the bug with a test. But this reasoning is fundamentally flawed: there is no
reason to believe there is a distribution of probability over the results of non-deterministic
operations. To put it in other words, what if I have an operation which returns a boolean
non-deterministically by sending a mail to Cueball asking him what the result should be. What is
the probability of Knuth answering true? That is non-sensical. He could very well decide to
always answer false in production, and true during the tests.

While this particular case might look a bit contrieved, there are similar situations that arise
/very/ often in real life. The typical example is when you use an underspecified API: the
behavior of whatever resource you're using is not fully described. When you test it locally, it
behaves in a certain way (that is coherent with its specification), but when you deploy it
somewhere else, the resource is implemented in a different way (which still adheres to the
specification), which screws up your code. The behavior of the resource is non-deterministic,
because several things might happen when you interact with it, but, in /your/ testing
environment, not all of the possible traces can actually happen. You can only see a subset of
them.

*** The ultimate challenger: UB
If you think carefully about what was said in the paragraph about the set of execution traces,
there are three possible cases, but we have only mentioned two:
- the set of execution traces is a singleton, the execution is deterministic, everything goes
  well;
- the set of execution traces has at least two traces, the execution is non-deterministic, things
  get /weird/;
- the set of executions traces is empty, things get /weirder/.

How could it be that the set of execution traces is empty? Intuitively, it doesn't make sense for
a programming language to have non-deterministic operations that simply have zero possible
outcomes (and diverging counts as an outcode). Yet, it turns out that most "low-level"
programming languages some operations are considered /Undefined Behavior/, that is, no defined
behavior corresponds to that operation. At the language abstract machine level, if you were to
try to "execute" a program with no valid execution trace, it would throw an error (but, with
respect to the program, it would be a meta-error, similar to a type error, not something that you
could catch). But, it is in general undecidable whether a given program leads to undefined
behavior, and compilers /have/ to output something when the behavior is not undefined, so /it
happens/ that a program with no behavior is executed. In this case, nothing has meaning anymore:
by observing the behavior of the /executed/ program, you can obtain no information on "its trace"
(since there is no such thing).

Typically, this is the difference between what the C standard calls "undefined behavior" and
"unspecified behavior". The former has no execution traces, the latter has more than one.

In particular, it is possible for a bug leading to undefined behavior not to be detectable by
simply witnessing the execution of a program. It might seem weird to say that a program has no
execution trace while it is clearly executing before your eyes; this is one of the common
pitfalls one might fall into while reasoning on UB. I suggest reading [[https://www.ralfj.de/blog/2019/07/14/uninit.html]["What the Hardware Does" is
not What Your Program Does]], which does a pretty good job at explaning why it's impossible to
test "at the hardware level" bugs that lead to UB.

** DONE The periodicity lemma: two elegant proofs   :computer_science:paper:
:PROPERTIES:
:EXPORT_FILE_NAME: word-periodicity-lemma
:EXPORT_DATE: 2023-11-07
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :math true
:END:
The periodicity lemma is a widely useful result about word combinatorics. Yet, the paper that if
often cited as the source for its proof, /Uniqueness Theorems for Periodic Functions/, uses very
unusual techniques in stringology.

#+begin_lemma
If a word \(w\) has periods \(p\) and \(q\), and is of length at least \(p+q-\gcd(p, q)\), then
\(w\) has period \(\gcd(p,q)\).
#+end_lemma

Before proving this stronger version of the lemma, let us state a weaker version. The point is
that this alternative version has a purely combinatorics proof, that is also interesting /per
se/.

#+begin_lemma
If a word \(w\) has periods \(p\) and \(q\), and is of length at least \(p+q\), then \(w\) has
period \(\gcd(p, q)\).
#+end_lemma
#+begin_proof
Assume \(q\geq p\). We are going to mimick Euclid's algorithm for computing \(\gcd(p, q)\). If
\(p=q\), the result is clear.

Otherwise, let \(i \leq |w|-(q-p)\) be a position in \(w\). If \(q\leq |w|\),
\(w[i]=w[i+q]\). Futhermore, \(w[i+q-p]=w[i+q]\). Hence \[w[i]=w[i+(q-p)]\]
Similarly, in the case, \(i-p\geq1\), and therefore \(w[i-p]=w[i]\). Since \(w[i-p]=w[i-p+q]\),
we have the same result. This means that \(q-p\) is a period of \(|w|\).

Note that \(\gcd(p, q-p)=\gcd(q, p)\) and that we certainly have \(p+(q-p)-\gcd(p,
q)\leq|w|\). By induction (on \(p+q\), for instance"), the result holds.
#+end_proof

*** A useful fact
Before giving two proofs of the lemma, we are going to show a very simple fact that will turn out
to be useful for both proofs.

#+begin_fact
Let \(w\) be a word with periods \(p\) and \(q\). \(w\) has period \(\gcd(p, q)\) if, and only
if, it can be extended in an infinite word that also has periods \(p\) and \(q\).
#+end_fact
#+begin_proof
If \(w\) is \(\gcd(p, q)\)-periodic, then it can be extended to an infinite word that is
\(\gcd(p, q)\)-periodic, and thus, that is also \(p\) and \(q\) periodic.

Conversely, if \(w\) can be extended in such an infinite word \(\hat{w}\), then \(\hat{w}\) is
\(\gcd(p,q)\)-periodic (which can be seen using the same proof as in the weak form of the
lemma). Hence, since \(w\) is a subword of \(\hat{w}\), it is also \(\gcd(p,q)\)-periodic.
#+end_proof

*** Formal series proof
Let us now, without further ado, give the first proof of the original lemma.
#+begin_proof
Consider \((a_n)_{n\in\mathbb{N}}\) (resp. \((b_n)_{n\in\mathbb{N}}\)) \(p\)-periodic (resp.
\(q\)-periodic) sequence which extends \(w\). Let \(F\) (resp. \(G\)) be the formal series \[
  F = \sum_{n=0}^\infty a_n X^n
\] respectively \[
  G = \sum_{n=0}^\infty b_n X^n
\]
By periodicity of \((a_n)\) and \((b_n)\), there exists polynomials \(P\) and \(Q\) of degree at
most, respectively, \(p-1\) and \(q-1\), such that \(F=(1-X^p)^{-1}P\) and \(G=(1-X^q)^{-1}Q\).

Then, let \(H=F-G\). We can write \(H=\dfrac{(1-X^q)P-(1-X^p)Q}{(1-X^p)(1-X^q)}\). Since \[
1-X^{\gcd(p, q)}\mid{}1-X^p,1-X^q \] and since the degree of \((1-X^q)P-(1-X^p)Q\) is at most
\(R\) is at most \(p+q-\gcd(p,q)\). Hence, \[R = H\dfrac{(1-X^p)}{1-X^{\gcd(p,q)}} \equiv
0\mod{}X^{p+q-\gcd(p,q)}\] because, by hypothesis, \(H \equiv 0 \mod{} X^{p+q-\gcd(p,q)}\) and
\(\dfrac{(1-X^p)(1-X^q)}{1-X^{\gcd(p,q)}}\) is a polynomial.

Hence, \(R=0\) and thus \(H=0\), proving that \(F=G\). By using the Fact, we have that \(w\) is
\(\gcd(p, q)\)-periodic.
#+end_proof

*** Linear algebra proof
This second proof of the lemma will prove a slightly stronger statement: the length bound of
\(p+q-\gcd(p,q)\) is optimal, that is, for any \(p\) and \(q\), there is a word \(w\) with
periods \(p\) and \(q\) of length \(p+q-\gcd(p,q)-1\) and which is not \(\gcd(p,q)\)-periodic.

#+begin_proof
As before, consider \(a\) and \(b\) the sequences that extend \(w\) and that are, respectively,
\(p\) and \(q\) periodic. By Fourier transform, there exists
\((c_\omega)_{\omega\in\mathbb{U}_p}\) and \((d_\xi)_{\xi\in\mathbb{U}_q}\), such that, for all
\(n\in\mathbb{N}\), \[ a_n = \sum_{\omega\in\mathbb{U}_p} c_\omega \omega^n \] and \[ b_n =
\sum_{\xi\in\mathbb{U}_q} d_\xi xi^n \]

Now, by hypothesis, for any \(n=1,\ldots,p+q-\gcd(p,q)\), we have \(a_n-b_n=0\). This defines a
system of \(p+q-\gcd(p,q)\) linear equation in the \(p+q-\gcd(p,q)\) unknowns \(c_\omega\),
\(-d_\xi\) for \(\omega\neq\xi\) and \(c_\omega-d_\xi\) for \(\omega=\xi\). The matrix of this
system is a Vandermonde matrix, hence it is non-singular. Thus, for \(\omega \in \mathbb{U}_p
\backslash \mathbb{U}_q\), \(c_\omega=0\) (and similarly for \(q\)-th root of the unity \(\xi\)
which are not also \(p\)-th root of the unity, \(d_\xi=0\)), and for other \(\omega=\xi \in
\mathbb{U}_p \cap \mathbb{U}_q\), \(c_\omega=d_\xi\). Therefore, for all \(n\in\mathbb{N}\),
\(a_n=b_n\). In particular, using the Fact, \(w\) is \(\gcd(p,q)\)-periodic.
#+end_proof

Observe that, if we had less that \(p+q-\gcd(p,q)\) equations, then there would be a non-trivial
linear subspace of solutions \((a, b)\) whose common prefix is \(p\)- and \(q\)-periodic. But,
only one point of that linear subspace hasa a common prefix that is \(\gcd(p,q)\)-periodic.

** DONE A defense of OCaml          :computer_science:programming_languages:
:PROPERTIES:
:EXPORT_FILE_NAME: ocaml-defense
:EXPORT_DATE: 2024-06-09
:END:
OCaml is a somewhat niche programming language. It lives in the small island of functional
programming languages, but it's often compared, not very favourably, with Haskell. This makes
OCaml niche even among its peer FP languages. Yet, OCaml has a very interesting feature
combination that, in my opinion, makes it stand out, even when compared to Haskell.

Note that, in all this post, I am going to compare a lot OCaml with Haskell, yet it shouldn't be
read as a comparison between the two languages. I chose Haskell to stand for whetever other
similar programming language there is on the small island of function programming languages,
because it is, to my knowledge, the most famous and used among those.

*** The pain points of OCaml

While I am going to show certain unique features of OCaml in this post, to be fair, I have to
start with a list of OCaml non-features. After all, the usual arguments that are made against
OCaml, especially in favour of Haskell, are valid, and it would be dishonest to just ignore them
to claim how good a language OCaml is.

**** Type classes

#+begin_quote
There once was a happy programmer, you, who had to perform computations using floating point
numbers (which made them less of a happy human being). As a perfectly normal person, you used an
large amount of =+=, =/= and =*= before launching the compiler and leaving the room to get a
coffee[fn:coffee-note], confident that you did a good job, and that everything would work fine.

When you sat again on their chair to see how perfectly well everything went, you felt a sudden
shock: dozens and dozens of type error, claiming that =This expression has type float but an
expression was expected of type int=. /Quick, quick, get the manual, what is this sorcery/, you
thought, as you reached for the beloved book. You felt disgust when you read[fn:ocaml-manual-float]

#+begin_blockquote
Notice also that integers and float-point numbers are distinct types, with distinct operators:
=+= and =*= operate on integers, but =+.= and =*.= operate on float.
#+end_blockquote
Painfully, you go through your whole codebase, making the appropriate changes. You compile again.
This time, there is no longer optimism, you don't leave your desktop for a coffee. After a short
time, the compilation ends, this time with no errors. /Ah/, you think, /this time things must
have worked out as expected/. Then you run your program, and you get an awfully uninformative
error

#+begin_src ocaml
  Exception: Invalid_argument "compare: functional value".
#+end_src

You get to the manual once again (from now on, that's a tab you're never closing again). After a
couple of minutes, you realize with horror what this is: this error message is a /runtime type
error/. It's a world that crumbles under your feet: you thought types were a compile-time only
thing, and that "well-typed programs can't go wrong"[fn:robin-quote], and that OCaml had type
safety, and that, at this rate, you might as well program directly in assembly, at least you'll
/known/ that you're going to get screwed.
#+end_quote

This tale of horror shows well the kind of idiosyncrasies found in OCaml that are very elegantly
solved in Haskell with type classes. The problem is that, in OCaml, polymorphic functions cannot
constraint they type they are polymorphic over[fn:exception-constraints]. A polymorphic function
/has/ to work for any type, and it has to consider the given type as opaque. This means that
there is no way to write a single addition function that works both for integers and for floating
point numbers. The Haskell-like solution would be to make the =add= function take the /actual/
=add= implementation as an argument, ie.

#+begin_src ocaml
let add (add_impl : 'a -> 'a -> 'a) (x : 'a) (y : 'a) : 'a =
  add_impl x y
#+end_src

the trick being that the compiler is automatically capable of inferring what =add_impl= should
be, so that if you write =add 3 4=, the compiler would make it become =add (+) 3 4=, whereas if
you wrote instead =add 3.0 4.0=, the compiler would have made it become =add (+.) 3.0 4.0=.
However, in OCaml, we cannot mimic that feature, as the compiler doesn't do that, and so our
=add= function is basically useless. Instead of =add (+) 3 4=, one might as well write =3 + 4=.

The second issue in our tale is due to a similar problem, which was worked around differently in
OCaml. The problem arises with the equality test === (or any comparison function, actually). I
can write src_ocaml[:exports code]{3 = 4} and src_ocaml[:exports code]{3.0 = 4.0}, so
src_ocaml[:exports code]{(=)} has to be polymorphic; but the actual comparison cannot be the same
for every type, ie. you don't compare for equality an integer as you would, say, a record. To
work around this, the src_ocaml[:exports code]{(=)} function is "compiler magic", ie. you
couldn't write it yourself, you have to rely on the compiler internals secretly exposed, which
is, by itself, not very pretty. And, in this case, you can't have a ==.= version just for float,
because you need to be able to compare every type that the user can create, so the "compiler
magic" is needed.

However, there is still an issue with this approach: there are some types for which it doesn't
make sense to instantiate the polymorphic equality. For instance, OCaml doesn't know how to
compare function for equality. And so, indeed, if you try src_ocaml[:exports code]{Fun.(id =
id)}, you get the aforementioned runtime error. Ugh.

In Haskell (and, more generally, in programming languages that use type classes), there are no
such problems: instances of a given type class are created just for types for which it makes
sense.  What this means, if you don't know what type classes are, is that, using the same
addition example as before, the only =add_impl= function the compiler knows about, and is allowed
to implicitly insert, are registered by the user. Similarly for the equality, if no one registers
the equality comparison for functions, the compiler could never accept src_ocaml[:exports
code]{Fun.(id = id)}.

While the situation might look very bleak, people at OCaml are working on modular implicits,
which, as its name suggest, would be a way to make the compiler implicitely pass modules as
function arguments, similarly to how the Haskell compiler implicitely passes instances of type
classes as function arguments. It's not quite the same thing, but in the end, would permit a very
similar kind of polymorphism.

**** Monads

One other key feature that OCaml lacks with respect to other function programming languages are
monads. Monads in other function programming languages are implemented as type classes, which
don't exist in OCaml. But even if they did, monads also need rank-2 polymorphism. That's a
mouthful, but an example should make that sentence clear. Consider a plausible yet simple
definition for monads in Lean[fn:lean-not-haskell]:

#+begin_src lean4
  class Monad (m : Type → Type) where
    pure : α → m α
    bind : m α → (α → m β) → m β
#+end_src

You might not understand all of this definition, but the important part is the first line, and
more specifically =m : Type → Type=, where =Type= is the type of types (ie. =String : Type=). The
type =Type → Type= corresponds to type families over types, or, said in another way, types which
are themselves polymorphic. A good example would be ='a list=: it can be thought as a kind of
"function" which associates a concrete type =int= to a concrete type =int list=. That's important
because, as you can see, in the rest of the definition, =m= is instantiated with different
arguments. While ='a list= makes sense in OCaml, we cannot talk of just =list= alone, as the
"function" which associates any type ='a= to a ='a list=. That's a big deal, and prevents us from
defining monads.

Just as loops and procedures are great, powerful and general-purpose abstractions whose absence
you really feel when programming in a programming language that doesn't have those (such as
assembly), monads are very powerful abstraction that are used *a lot* in programming languages
that have them, and that match very well the usual idioms of functional programming. This is why
people push them a lot as an argument when comparing Haskell and OCaml.

In fact, OCaml has, over the years, been percolated through by ideas, idioms and naming
conventions that stem from monadic programming. Some examples include
- the =Option.bind= name (it's the same =bind= as in the definition above, where =m= would be
  =option=)
- the =let= operators, whose purpose is to mimic the =do= notation

In fact, even though monads cannot be expression with the core type system of OCaml, they can be
expressed using modules (which is why people are interested in making the compiler capable of
implicitely adding module arguments, and not just "regular" value arguments):

#+begin_src ocaml
module type Monad = sig
  type 'a t
  val return : 'a -> 'a t
  val bind : 'a t -> ('a -> 'b t) -> 'b t
end
#+end_src

While this definition is not present in the standard library, it is in the alternative standard
library developed by Jane Street, =Core=. It's still not as practical to use as in Haskell,
mainly because of the lack of implicit arguments, lack of =do= notation, and because it's not as
widely used in the rest of the ecosystem. There also are some rough edges, and sometimes working
extensively with modules as first class values requires using lesser-known OCaml features, such
as locally abstract types, for which, unless you already know they exist, you'll get no help from
the compiler error messages.

*** Where OCaml shines

After all of what I've said, you might be convinced never to use OCaml again. After all, it seems
that Haskell is just a better version of OCaml. A *pure* version of OCaml.

**** Purity

Indeed, an important argument that is made against OCaml with respect to Haskell, of which I
haven't discussed yet, is its lack of purity. OCaml has some imperative aspects, and it doesn't
even try to hide them! Functional programming people are usually very much aware of the
advantages of not having imperative idioms in their code base, so they tend to see every
occurrence of imperative programming as a lost occasion of doing something better, ie. in a more
functional (and thus elegant) way. And, while part of me strongly agrees with this (almost
simplistic) view of the world, there is also something interesting that rises out of the
intersection of pure, functional programming and imperative programming. Something that goes
beyond trying to stitch a functional program together with an imperative one, turning them into
an abomination of nature.

#+caption: Haskemblyfuck, a chimera based on Haskell, assembly and brainfuck (don't do this at home)
[[/images/chimera.avif#center]]

Indeed, programming languages like OCaml are ideal for data structures called "semi-persistent".
To undestand what that means, let's make a little digression on data structures. Data structures
(and algorithmics in general), are presented in an imperative fashion: the underlying model
usually is (based on) Turing machines.  Persistent data structures are those for which, even
after modifying them, every "version" is still available, ie. every state of the data structure
between two mutable operations on them is still accessible as it was "back then", and can be in
turn operated onto as if nothing happened to it.  While this is a peculiar property for
imperative data structures, (one that is usually hard to implement efficiently for an arbitrary
data structure), this is very similar to how data structures work out-of-the-box in pure
functional programming languages. Indeed, purely functional data structures cannot be mutated, so
if one still has a pointer to a certain version of a data structure, the underlying data must be
as it was when it was created; and it can freely be used without fear of breaking someone else's
data.  However, it should to be noted that persistent data structure in general need not to be
implemented using immutability. They should just exhibit observational immutability.

This is were OCaml kicks in: Conchon and Filliâtre built[fn:conchon-filliatre] several
semi-peristent (a weaker, yet still useful in pratice, version of persistence) version of
classical and widely used data structures, such as arrays, lists and hash tables, in OCaml. These
data structures particularly shine because they exhibit imperative-like tight complexity,
performance wise, and yet pure functional-like signatures, with the same guarantees one has with
such immutable data structures. This is only possible in a language where it is highly idiomatic
to program in a functional fashion, yet imperative code is still possible, without additional
abstraction costs to "bridge the gap". That gives you the best of both worlds: efficient
implementations with strong semantic promises. And, indeed, this is how every functional
programming is, in the end compiled. Even Haskell has to do, behind the scenes, imperative stuff.
The difference is that, in OCaml, this is a first class feature, rather than something people
should be afraid of. Of course, this has a cost: beyond the stigma associated with non-purity in
OCaml, this also makes it possible to /actually write imperative code that doesn't behave as if
everything was purely immutable/, which can be a curse.

But my point is, OCaml being non-pure is not a bug, or a hideous part of the language people
prefer not to look at. It's a feature. It has its limitations, but it's still a feature. That
Haskell doesn't have. And, in fact, one might argue that Haskell's way to cope for the
performance gap is lazyness[fn:functional-gap].

**** Compiler efficiency

An argument that I also often hear in favour of Haskell is that it has a /very/ good compiler,
whereas OCaml's compiler is "just good". Don't get me wrong, both languages have compilers with
tens of year of engineering and fine-tuning, backed up by a significant amount of theoretical
work and wise language design. It's just that Haskell's compiler really seems to be very, /very/
good[fn:haskell-compiler-quality].

However, to me, it seems that this is due to the amount of costly abstraction that Haskell piles
up. Basically, Haskell has too many abstractions to be very competitive on the efficiency of the
generated code, unless its compiler does a lot of optimisations. And it's what it does. OCaml, on
the other hand, has much less abstractions, and the more costly ones are also the niche ones that
I barely ever see used (even though I do not claim to have seen a representative sample of all
OCaml programs). In fact, OCaml has a /more/ optimizing compiler, called flambda, which, besides
making the "regular code" generate faster maching code (in general), also makes those costly
abstractions much less expensive. But it's not even the default compiler. Because, for most
usages, the usual compiler provides good enough performance, and, importantly, is very
predictable in the performance of the generated code, a property that the Haskell compiler lacks
(and apparently some find very annoying).

A good example is the definition of the composition operator found in Haskell's =Prelude=:

#+begin_src haskell
  {-# INLINE (.) #-}
  -- Make sure it has TWO args only on the left, so that it inlines
  -- when applied to two functions, even if there is no final argument
  (.)    :: (b -> c) -> (a -> b) -> a -> c
  (.) f g = \x -> f (g x)
#+end_src

Funnily enough, to make sure that the optimiser does the right thing, this definition has to be
tagged as =INLINE=, it has to be written in a way that it will be inlined as wanted, /and/ there
has to be a comment indicating that it's defined as so for a good reason. This shows you how
brittle Haskell's optimizer can be, despite the fact that optimization is very important for that
language.

This also makes OCaml a suitable target language for a compiler, in that there are no risks of
the OCaml compiler blowing up in your face.

**** Software architecture
An other interesting aspect of OCaml is its support for several programming paradigms, that allow
different architecture design. A concrete example of this very vague-sounding sentence is
introduced by considering a game containing various entities, like monsters (zombies, skeletons,
...), passive entities, and so on and so forth. In an object oriented programming language, these
might be represented by a class hierarchy, at the root of which might be the abstract entity
class, down to a, say zombie class. The behavior for entities is specified by methods, which are
implemented in each class. In a function programming language, instead, these might be
represented using algebraic data types. The behavior for entities is specified in functions that
pattern match on the entities. These might look like similar solutions in different paradigm, but
are, in fact, quite different.

For instance, think now that I want to add a new creature in my game. In the OO version, that
involves creating a new class that subclasses whatever appropriate parent class in the hierarchy.
This is good, because it's a local change. I don't need to revisit all my existing code base to
do so. In fact, I could even do so if I had to link against a precompiled piece of code, having
only access to header declarations.

In my ADT solution, however, things are not so simple. Not only I have to modify the type that
holds every possible entity in my game, which requires having access to said code, and not just
the binaries, but I also have to modify every single "behavior" function that pattern matches on
entities, because I've added a new case. It's a highly non-local change.

Now, imagine that, rather than adding a new kind of entity, I'd rather add a new kind of
behavior. In the OO setting, that means adding a new method, which means modifying the whole
hierarchy. The behavior is tighly coupled with each entity. In my AST setup, though, adding a new
behavior just means defining a new function, which can be done locally.

In short, code that relies on dynamic dispatch makes vertical extensions (those where you add a
new case) easy, because the behavior is bundled with the objects themselves. Matching-based code
makes horizontal extensions easy, exactly because behavior is not coupled with the data.

Most programming languages have quite an opinionated view on whether you should rely on dynamic
dispatch, or case switching. In pure OO languages, for instance, it is considered not idiomatic
to test whether a given object is of a given type. Think of duck typing, "/if it walks like a
duck, and it quacks like a duck, then it must be a duck/". They try to work around the
difficulties of making horizontal extensions by using hooks, double dispatch, and other kind of
OO patterns. In OCaml, you are gently pushed towards the other end of the spectrum, as the most
natural way to encode problems is usually with ADTs. However, OCaml has a very wide palette of
features that allow you to trade off horizontal extensionability for vertical extensionability.

Of course, you might be tempted to remind yourself that the '/O/' in OCaml stands for
/objective/, which means that OCaml should be an OO language. While technically true, and while
OCaml has a quite original yet featureful object paradigm, it's a feature that I very rarely see
used in practice. In fact, it might be the single one feature of OCaml I have never seen used in
a real life project[fn:ocaml-unused-feature]. But there are other alternatives.

For instance, exceptions in OCaml are open-ended, meaning that anyone can define new exceptions
and throw one in your code, so you can't possibly handle them all, except in a uniform way that
is not aware of the exact kind of exception. This is an example of a more general feature of
OCaml, open sum types, which are sum types for which everyone can add variants. The pattern
matching on these types is a bit peculiar, because the only way to can make it exhaustive is by
adding a catchall pattern.

The more featureful way to have dynamic dispatch is to use first-class modules. Not only it
nicely integrates with the rest of the OCaml ecosystem, and especially nicely with functors, but
it is /more expressive/ than "regular" dynamic dispatch, because modules do not just bundle
values (which covers both an internal state and "methods"), but also types (and even type
families, which is how you can encode higher sorted polymorphism in OCaml) and modules. Modules
are also /extra nice/ because they do not necessarily entail dynamic dispatch, and because the
modular implicits planned feature --- the one that is supposed to get rid of the very first pain
point I mentioned --- relies on, well, modules.

But the greatest part of it is that OCaml has plenty of features for various kind of dynamic
dispatch (and I haven't even talked about polymorphic variants, and the row polymorphism that
goes with them), so that you can pick the most appropriate one for your problem. Most of the
time, you won't need those, but they're always availble. And they all integrate nicely with each
other[fn:integration-performance], which means that even if other parts of your code do not use
objects at all, you can still make them interact with object-based pieces of code.


[fn:coffee-note] You don't like coffee? Yeah, well, me neither, but I still get a cup of coffee
    before compiling code, because I see many of my peers do so, so I believe it's a good omen or
    something like that. You'll tell me that this is [[https://en.wikipedia.org/wiki/Cargo_cult_programming][cargo cult]], and I'll answer you that I've
    seen so many people apply cargo cult and get working(ish) results in the end that I believe
    in cargo cult being a proper way of doing things. You'll tell me that this is meta-cargo
    cult, and I'll politely remind you that this post is neither about coffee nor cargo cult, so
    if you could stop interrupting me, it would be nice.

[fn:ocaml-manual-float] You don't believe me? And yet, [[https://www.ocaml.org/manual/5.2/coreexamples.html#s%3Abasics][there it is]].

[fn:robin-quote] That quotation is from Robin Milner, and comes from /[[https://doi.org/10.1016%2F0022-0000%2878%2990014-4][A Theory of Type Polymorphism
in Programming]]/.

[fn:exception-constraints] Except for row polymorphism, which might be seen as parametric
    polymorphism with constraints. But for our problem, row polymorphism cannot help.

[fn:lean-not-haskell] Even though I've mentioned Haskell a lot in this post, I only did so because
    it's (as far as I know) the most widely used and known functional programming language with a
    very expressive type system, type classes, and all the good stuff. Yet, I am more acquainted
    with Lean, which, for what we are interested into, is very similar. So, whenever I need to
    write snippets of code in a FP language that supports type classes, it will be Lean.

[fn:conchon-filliatre] They do so in /[[https://doi.org/10.1007/978-3-540-78739-6_25][Semi-persistent Data Structures]]/.

[fn:functional-gap] There exists a theoretical "gap" between how efficient you can write algorithms
    in a purely functional fashion and in an imperative fashion. That gap is, at most, a
    logarithmic factor, and there exists some problems for which there is indeed to purely
    functional algorithm that is faster than its imperative counterpart times a logarithmic
    factor. But this only applies to /eager/ purely functional programs. See /[[https://dog.org/10.1145/244795.244798][Pure vs. Impure
    Lisp]]/.  Of course, this overlooks the fact that modern computers have an inherently
    imperative architecture, and that programming in a pure functional fashion requires relying
    on abstractions, which can be expensive on their own. This is especially true in Haskell,
    where the difference of performance between the naive version of the code generated and the
    optimized one is very important, because their code generation generates /a lot/ of stuff.

[fn:haskell-compiler-quality] I have to admit that this is not something that I have personally
    checked. I have never run compiler benchmarks comparing Haskell and OCaml, nor have I ever
    read their source code to evaluate the efficiency of the algorithms used and which
    optimisations are done. But this is something that I hear from people who have done so, so I
    am rather inclined in trusting it.

[fn:ocaml-unused-feature] Well, I lied. There is also higher ranked polymorphism.  And there's
    recursive modules too.  And irregular types.  And explicitly polymorphic type ascriptions.
    And... actually OCaml is pretty full of features I've never seen used.

[fn:integration-performance] Up to performance consideration: objects and polymorphic variants
    are, essentially, hash tables, which are much less performant than module values or ADTs. So,
    sure, you can use them without fear of incompatibility, but in practice it's a good thing
    that you don't.

** TODO A case against language specific package managers :sysadmin:computer_science:
:PROPERTIES:
:EXPORT_DATE: 2024-06-14
:EXPORT_FILE_NAME: case-against-language-package-manager
:END:
Recently, I found myself frequently and vividly discussing the merits of language-specific
package managers, by which I mean tools that auto-magically handle dependencies for the
developer, by taking care of fetching them, installing them somewhere, making them available to
subsequent build steps; but also take care of uninstalling dependencies that used to be useful,
updating to newer versions, and, more generally, organizing the local environment for that
programming language. If you only have ever used modern tools, you may think this is an easy
task, and that nothing can go wrong. Yet, it used to be the case that, even in popular
programming languages, this was handled extremely poorly[fn:xkcd-argument].

[[https://imgs.xkcd.com/comics/python_environment.png#center]]

Opposed to language-specific package managers are system package managers, ie. package managers
which are not tied to a specific programming language, and thus are suited to handle your whole
system.

My claim is that the ecosystem of a programming language should *maximally decouple their
language-specific package manager* (if they have any) *from any other component of the
ecosystem*, and view it as one possible way to install dependencies for a developer, rather than
the canonical one, excluding any other package manager from being officially supported.

There are some exceptions for this rule, on which I will come back at the end of this post; but,
as far as I see it, they do not represent the majority of the case. The "default" design of an
ecosystem should be to integrate nicely with any package manager, and, in some specific
situations, one could consider the trade off of having a single package manager to think of,
designed specifically for the ecosystem it belongs to.

To be more precise, I think that, in most situations, not having a tightly coupled
language-specific package manager has the following advantages over having one:
- less burden on the maintainers of the ecosystem:
  - for the packaging, they are helped by an army of packagers from various communities
  - they don't /have/ to maintain a package manager
  - but if they do, it is still helpful to have a clear abstraction boundary between the package
    manager --- that does only that --- and the rest of the ecosystem; this means it's easier to
    design the package manager properly, with low coupling, because a natural boundary is already
    present there
- more freedom for the end user:
  - by making components more modular, you ease the development of alternatives for some specific
    components, which might fit better the particular use case of certain users
  - by allowing the user to chose the package manager they prefer, you don't enforce your point
    of view of how a package manager should work to a user that might think differently; this is
    important because, package managers usually not being the center of expertise of people
    developing programming languages, it is most likely that their point of view on the matter is
    not the most enlighten one, and therefore users who disagree with it might have good reasons
    to disagree with you
- less burden on the end user:
  - by forcing the user to use a specific tool that they haven't used previously, because it was
    designed specifically for one ecosystem, you are forcing them to learn how to use it
  - beyond the considerations for a /single/ ecosystem, if it were to become the norm for every
    ecosystem to have its specific tooling that is always exclusively designed for it, and didn't
    work in any other context, it makes it harder for less tech-savvy people to use they computer
    daily, because there are no fit-all-sizes tools they can use in most situations

*** Limited scope
**** Specifying dependencies outside of the ecosystem
**** More complex build steps
**** How to distribute software
*** Less featerful than system package managers
**** Reproducibility issues
**** System state
**** Coherent state
*** Distributed or anarchic?
**** No global indexing
**** No sharing

[fn:xkcd-argument] Rather than citing some thorough studies to back up this claim, I'm just going to
insert an XKCD comic making the same point. I think that, if it becomes a meme how poorly you do
something, it becomes superfluous to argue any further.

* Home
:PROPERTIES:
:EXPORT_HUGO_SECTION: /
:END:
** Search
:PROPERTIES:
:EXPORT_HUGO_CUSTOM_FRONT_MATTER: :layout search
:EXPORT_FILE_NAME: search
:END:
